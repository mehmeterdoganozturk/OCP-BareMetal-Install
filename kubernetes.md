# Ubuntu 24.04 Ãœzerine HA Kubernetes Cluster Kurulumu (3 Master, 3 Worker + HAProxy)

![AÃ§Ä±klama](./images/kubernetes-diyagram.png){ width=600 }


Bu dokÃ¼man, Ubuntu 24.04 LTS sunucular kullanarak 3 Master ve 3 Worker dÃ¼ÄŸÃ¼mden oluÅŸan, Ã¶nÃ¼nde HAProxy ile yÃ¼ksek eriÅŸilebilirlik (HA) saÄŸlayan bir Kubernetes cluster'Ä±nÄ±n `kubeadm` ile nasÄ±l kurulacaÄŸÄ±nÄ± adÄ±m adÄ±m aÃ§Ä±klamaktadÄ±r.

## Genel Mimari

* **HAProxy (1 Sunucu/VM):** Kubernetes API sunucusuna (Kontrol DÃ¼zlemi - Port 6443) gelen istekleri 3 Master dÃ¼ÄŸÃ¼me daÄŸÄ±tarak kontrol dÃ¼zlemi iÃ§in HA saÄŸlar.
* **Master DÃ¼ÄŸÃ¼mler (3 Sunucu/VM):** Kubernetes kontrol dÃ¼zlemi bileÅŸenlerini (API Server, etcd, Scheduler, Controller Manager) Ã§alÄ±ÅŸtÄ±rÄ±r.
* **Worker DÃ¼ÄŸÃ¼mler (3 Sunucu/VM):** Uygulama Pod'larÄ±nÄ± barÄ±ndÄ±rÄ±r (Kubelet, Kube-proxy Ã§alÄ±ÅŸÄ±r).

## Ã–nemli Notlar

* Bu kÄ±lavuz `kubeadm` kullanÄ±r. FarklÄ± kurulum yÃ¶ntemleri mevcuttur.
* Komutlar `root` veya `sudo` yetkisi gerektirir.
* TÃ¼m sunucularÄ±n belirtilen portlar Ã¼zerinden birbirleriyle ve HAProxy ile iletiÅŸim kurabildiÄŸinden emin olun (Firewall ayarlarÄ±).
* IP adreslerini ve hostname'leri kendi ortamÄ±nÄ±za gÃ¶re **mutlaka** deÄŸiÅŸtirin.
* Kuruluma baÅŸlamadan Ã¶nce tÃ¼m sunucularÄ±n gÃ¼ncel olduÄŸundan emin olun (`sudo apt update && sudo apt upgrade -y`).

## AdÄ±m 1: Ã–n HazÄ±rlÄ±klar (TÃ¼m Sunucular: HAProxy, 3 Master, 3 Worker)

```
network:
  version: 2
  ethernets:
    enp0s3:
      dhcp4: true
    enp0s8:
      dhcp4: no
      addresses:
        - 192.168.57.102/24
      # gateway4: 192.168.57.1
      # nameservers:
      #   addresses: [8.8.8.8, 1.1.1.1]
```

1.  **Ä°ÅŸletim Sistemi:** Ubuntu 24.04 LTS Server.
2.  **Statik IP Adresleri (Ã–rnek):**
    * HAProxy: `192.168.57.100` (**API Endpoint**)
    * Master 1: `192.168.57.101`
    * Master 2: `192.168.57.102`
    * Master 3: `192.168.57.103`
    * Worker 1: `192.168.57.111`
    * Worker 2: `192.168.57.112`
    * Worker 3: `192.168.57.113`



    ```
    alias update='sudo apt-get update && sudo apt-get upgrade -y && sudo apt-get dist-upgrade -y && sudo apt autoremove -y'
    ```

    ```
    sudo hostnamectl set-hostname haproxy.lab.local
    sudo hostnamectl set-hostname master1.lab.local
    sudo hostnamectl set-hostname master2.lab.local
    sudo hostnamectl set-hostname master3.lab.local
    sudo hostnamectl set-hostname worker1.lab.local
    sudo hostnamectl set-hostname worker2.lab.local
    sudo hostnamectl set-hostname worker3.lab.local
    ```
3.  **Hostname & /etc/hosts AyarlarÄ±:** Her sunucuya anlamlÄ± bir hostname verin ve tÃ¼m sunuculardaki `/etc/hosts` dosyasÄ±nÄ± aÅŸaÄŸÄ±daki gibi gÃ¼ncelleyin:
    ```
    192.168.57.100 haproxy haproxy.lab.local
    192.168.57.101 master1 master1.lab.local
    192.168.57.102 master2 master2.lab.local
    192.168.57.103 master3 master3.lab.local
    192.168.57.111 worker1 worker1.lab.local
    192.168.57.112 worker2 worker2.lab.local
    192.168.57.113 worker3 worker3.lab.local
    ```
4.  **Gerekli Portlar (Firewall Ä°zinleri):**
    * **Master DÃ¼ÄŸÃ¼mler:** TCP 6443, 2379-2380, 10250, 10257, 10259
    * **Worker DÃ¼ÄŸÃ¼mler:** TCP 10250, 30000-32767 (NodePort AralÄ±ÄŸÄ±)
    * **HAProxy:** TCP 6443 (Gelen)
    * **TÃ¼m DÃ¼ÄŸÃ¼mler (CNI - Ã–rnek Calico):** TCP 179, UDP 4789, IP Protocol 4

## AdÄ±m 2: HAProxy Kurulumu ve YapÄ±landÄ±rmasÄ± (HAProxy Sunucusu Ãœzerinde)

**Not:** HAProxy sadece **Master** dÃ¼ÄŸÃ¼mlerin API sunucusuna (6443) eriÅŸimi dengelemek iÃ§indir. Worker dÃ¼ÄŸÃ¼mler buraya **eklenmez**.

1.  **Kurulum:**
    ```bash
    sudo apt update
    sudo apt install haproxy -y
    ```

3.  **YapÄ±landÄ±rma (`/etc/haproxy/haproxy.cfg`):**
    ```cfg
    global
        log /dev/log local0
        log /dev/log local1 notice
        chroot /var/lib/haproxy
        stats socket /run/haproxy/admin.sock mode 660 level admin expose-fd listeners
        stats timeout 30s
        user haproxy
        group haproxy
        daemon
        maxconn 2048

    defaults
        log     global
        mode    tcp
        option  tcplog
        option  dontlognull
        timeout connect 5000ms
        timeout client  50000ms
        timeout server  50000ms
        timeout check   3s
    
    frontend kubernetes-api
        bind *:6443
        mode tcp
        option tcplog
        default_backend kubernetes-master-nodes

    backend kubernetes-master-nodes
        mode tcp
        balance roundrobin
        option tcp-check
        default-server inter 3s fall 3 rise 2
        server master1 10.100.0.24:6443 check
        server master2 10.100.0.25:6443 check
      server master3 10.100.0.26:6443 check

    listen stats
        bind *:9000
        mode http
        stats enable
        stats uri /
        stats refresh 10s
        stats show-node
        stats auth admin:MyS3cr3tPa$$  # gÃ¼Ã§lÃ¼ ve deÄŸiÅŸtirilmiÅŸ bir ÅŸifre
    ```
    
3.  **YapÄ±landÄ±rma (`/etc/haproxy/haproxy.cfg`):**
    ```cfg
    global
        log /dev/log    local0
        log /dev/log    local1 notice
        chroot /var/lib/haproxy
        stats socket /run/haproxy/admin.sock mode 660 level admin expose-fd listeners
        stats timeout 30s
        user haproxy
        group haproxy
        daemon

    defaults
        log     global
        mode    tcp
        option  tcplog
        option  dontlognull
        timeout connect 5000
        timeout client  50000
        timeout server  50000

    frontend kubernetes-api
        bind *:6443
        mode tcp
        option tcplog
        default_backend kubernetes-master-nodes

    backend kubernetes-master-nodes
        mode tcp
        option tcplog
        option tcp-check
        balance roundrobin
        # Kendi Master IP adreslerinizi buraya girin:
        server master1 192.168.57.101:6443 check fall 3 rise 2
        server master2 192.168.57.102:6443 check fall 3 rise 2
        server master3 192.168.57.103:6443 check fall 3 rise 2
    ```
4.  **Servis YÃ¶netimi:**
    ```bash
    sudo systemctl enable haproxy
    sudo systemctl restart haproxy
    sudo systemctl status haproxy
    ```

## AdÄ±m 3: Kubernetes BileÅŸenleri Ä°Ã§in HazÄ±rlÄ±k (TÃ¼m Master ve Worker DÃ¼ÄŸÃ¼mler Ãœzerinde)

AÅŸaÄŸÄ±daki adÄ±mlarÄ± **tÃ¼m 6 Kubernetes dÃ¼ÄŸÃ¼mÃ¼nde** gerÃ§ekleÅŸtirin:

1.  **Swap'Ä± Devre DÄ±ÅŸÄ± BÄ±rakma:**
    ```bash
    ***************************************************************************************************
    buradan tamamen kapat
    sudo nano /etc/fstab
    # /swap.img       none    swap    sw      0       0
    --------------------------------------------------------------
    # 1. Swap'Ä± geÃ§ici olarak kapat
    sudo swapoff -a

    # 2. /etc/fstab dosyasÄ±ndaki swap satÄ±rÄ±nÄ± yorum satÄ±rÄ±na al (swap'Ä± aÃ§mamayÄ± saÄŸlamak iÃ§in)
    sudo sed -i '/ swap / s/^\(.*\)$/#\1/g' /etc/fstab

    # 3. vm.swappiness deÄŸerini 0 yaparak swap kullanÄ±mÄ±nÄ± engelle
    echo "vm.swappiness=0" | sudo tee -a /etc/sysctl.conf

    # 4. YaptÄ±ÄŸÄ±n deÄŸiÅŸiklikleri uygulamak iÃ§in sysctl.conf dosyasÄ±nÄ± tekrar yÃ¼kle
    sudo sysctl -p
    free -h
    ***************************************************************************************************
    sudo swapoff -a
    sudo sed -i '/ swap / s/^\(.*\)$/#\1/g' /etc/fstab
    ```
2.  **Kernel ModÃ¼llerini YÃ¼kleme:**
    ```bash
    sudo modprobe overlay
    sudo modprobe br_netfilter

    cat <<EOF | sudo tee /etc/modules-load.d/k8s.conf
    overlay
    br_netfilter
    EOF
    -------------------------------------------------------------------------------------------------
    * Kubernetes iÃ§in gerekli olan iki Ã¶nemli kernel modÃ¼lÃ¼nÃ¼ yÃ¼kler (overlay ve br_netfilter).
    sistem yeniden baÅŸlatÄ±ldÄ±ÄŸÄ±nda bu modÃ¼llerin otomatik yÃ¼klenmesini saÄŸlar.

    * overlay modÃ¼lÃ¼, OverlayFS adÄ± verilen bir dosya sistemi tÃ¼rÃ¼nÃ¼ destekler.
    Kubernetes, Ã¶zellikle konteyner runtime'larÄ± (Ã¶rn. containerd, Docker) OverlayFSâ€™yi kullanarak container dosya sistemlerini 
    katmanlÄ± ÅŸekilde yÃ¶netir.

    * br_netfilter, Bu modÃ¼l, Linux bridgeâ€™leri Ã¼zerinden geÃ§en trafik iÃ§in iptables (netfilter) kurallarÄ±nÄ±n uygulanmasÄ±nÄ± saÄŸlar.
    Kubernetes, podâ€™lar arasÄ± aÄŸ trafiÄŸini yÃ¶netmek iÃ§in iptables ve bridge aÄŸlarÄ±nÄ± birlikte kullanÄ±r.
    Bu modÃ¼l olmadan bazÄ± aÄŸ kurallarÄ± dÃ¼zgÃ¼n Ã§alÄ±ÅŸmaz ve podâ€™lar arasÄ±nda iletiÅŸim sorunlarÄ± yaÅŸanabilir.
    -------------------------------------------------------------------------------------------------
   
    ```
3.  **Sysctl AyarlarÄ±:**
    ```bash
    cat <<EOF | sudo tee /etc/sysctl.d/k8s.conf
    net.bridge.bridge-nf-call-iptables  = 1
    net.bridge.bridge-nf-call-ip6tables = 1
    net.ipv4.ip_forward                 = 1
    EOF

    sudo sysctl --system

    -------------------------------------------------------------------------------------------------
    * Bu komutlar da Kubernetesâ€™in aÄŸ (networking) bileÅŸenlerinin doÄŸru Ã§alÄ±ÅŸmasÄ± iÃ§in gerekli olan kernel parametrelerini ayarlÄ±yor.
    * net.bridge.bridge-nf-call-iptables = 1, Bu ayar, Linux kÃ¶prÃ¼ aÄŸÄ± Ã¼zerinden geÃ§en trafiÄŸin iptables kurallarÄ±na takÄ±lmasÄ±nÄ± saÄŸlar.
    * net.ipv4.ip_forward = 1, Bu, IP yÃ¶nlendirmesini (IP forwarding) etkinleÅŸtirir. Bir podâ€™dan Ã§Ä±kan trafiÄŸin baÅŸka bir podâ€™a ya da servise yÃ¶nlendirilmesi iÃ§in gereklidir.
    * Bu aÃ§Ä±k deÄŸilse podâ€™lar ya da servisler birbirine ulaÅŸamaz.
    
    -------------------------------------------------------------------------------------------------
    ```
4.  **Container Runtime Kurulumu (containerd):**
    ```bash
    sudo apt update
    sudo apt install containerd -y

    sudo mkdir -p /etc/containerd
    sudo containerd config default | sudo tee /etc/containerd/config.toml
    sudo sed -i 's/SystemdCgroup = false/SystemdCgroup = true/g' /etc/containerd/config.toml

    sudo systemctl restart containerd
    sudo systemctl enable containerd
    ```
5.  **Kubernetes Paketlerini Kurma (kubeadm, kubelet, kubectl):**
    ```bash
    sudo apt-get install curl ca-certificates apt-transport-https  -y
    curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.31/deb/Release.key | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg
    echo "deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.31/deb/ /" | sudo tee /etc/apt/sources.list.d/kubernetes.list
    sudo apt update
    sudo apt install kubelet kubeadm kubectl -y
    -----------------------------------------------------------------------
    curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.30/deb/Release.key | sudo gpg --dearmor -o /usr/share/keyrings/kubernetes-archive-keyring.gpg
    echo "deb [signed-by=/usr/share/keyrings/kubernetes-archive-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.30/deb/ /" | sudo tee /etc/apt/sources.list.d/kubernetes.list
    sudo apt update
    sudo apt install -y kubelet kubeadm kubectl
    sudo systemctl enable kubelet
    sudo apt-mark hold kubelet kubeadm 
    ```

## AdÄ±m 4: Kontrol DÃ¼zlemini BaÅŸlatma (Sadece Ä°lk Master DÃ¼ÄŸÃ¼m - master1 Ãœzerinde)

1.  **kubeadm init:**
    ```bash
    # HAProxy IP'nizi ve seÃ§tiÄŸiniz Pod Network CIDR'Ä±nÄ± kullanÄ±n (Calico iÃ§in 10.244.0.0/16)
    sudo kubeadm init \
      --control-plane-endpoint "192.168.57.100:6443" \
      --upload-certs \
      --pod-network-cidr=10.244.0.0/16
    ```
    ----------------------------------------------------
    
    * --control-plane-endpoint "192.168.57.100:6443" Bu, kÃ¼meye dÄ±ÅŸarÄ±dan eriÅŸimde kullanÄ±lacak sanal adresi belirtir.
    * Genellikle bu adresin arkasÄ±nda bir Load Balancer (Ã¶rneÄŸin senin ortamÄ±nda HAProxy) olur. DiÄŸer kontrol dÃ¼zlemi dÃ¼ÄŸÃ¼mleri ve worker node'lar bu adrese baÄŸlanÄ±r.
    * 192.168.57.100: Kontrol dÃ¼zlemi dÃ¼ÄŸÃ¼mÃ¼nÃ¼n (veya birden fazla kontrol dÃ¼zlemi dÃ¼ÄŸÃ¼mÃ¼ varsa, bunlarÄ±n Ã¶nÃ¼ndeki bir yÃ¼k dengeleyicinin - load balancer) IP adresi veya DNS adÄ±dÄ±r. DiÄŸer dÃ¼ÄŸÃ¼mler bu    
    adres Ã¼zerinden API sunucusu ile konuÅŸur.
    * 6443: Kubernetes API sunucusunun varsayÄ±lan gÃ¼venli (HTTPS) portudur.

    --------------------------------------------------------------
3.  **Ã–NEMLÄ°:** Komut Ã§Ä±ktÄ±sÄ±ndaki `kubeadm join` komutlarÄ±nÄ± (hem master hem worker iÃ§in) ve `kubectl` yapÄ±landÄ±rma adÄ±mlarÄ±nÄ± **kaydedin**.
4.  **kubectl'i YapÄ±landÄ±r:** (Ã‡Ä±ktÄ±daki adÄ±mlarÄ± uygulayÄ±n)
    ```bash
    mkdir -p $HOME/.kube
    sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
    sudo chown $(id -u):$(id -g) $HOME/.kube/config
    ```
    * /etc/kubernetes/admin.conf: Bu dosya, kubeadm init tarafÄ±ndan oluÅŸturulan Kubernetes API eriÅŸim ayarlarÄ±nÄ± iÃ§erir.
    * kubectl bu dosyayÄ± okuyarak hangi clusterâ€™a baÄŸlanacaÄŸÄ±nÄ±, hangi kullanÄ±cÄ± ve sertifikayla baÄŸlanacaÄŸÄ±nÄ± bilir.



## AdÄ±m 5: DiÄŸer Master DÃ¼ÄŸÃ¼mleri Cluster'a Ekleme (master2 ve master3 Ãœzerinde)

1.  `master1`'deki `kubeadm init` Ã§Ä±ktÄ±sÄ±ndan aldÄ±ÄŸÄ±nÄ±z **Master join komutunu** `master2` ve `master3` Ã¼zerinde `sudo` ile Ã§alÄ±ÅŸtÄ±rÄ±n. Komut ÅŸuna benzer olacaktÄ±r:
    ```bash
    # Ã–RNEKTÄ°R! Kendi Ã§Ä±ktÄ±nÄ±zdaki komutu kullanÄ±n!
    sudo kubeadm join 192.168.57.100:6443 --token <token> \
        --discovery-token-ca-cert-hash sha256:<hash> \
        --control-plane --certificate-key <certificate_key>
    ```

## AdÄ±m 6: Pod Network (CNI) Kurulumu (Sadece Bir Master DÃ¼ÄŸÃ¼m Ãœzerinde)

1.  Bir CNI eklentisi (Ã¶rneÄŸin Calico) kurun. `kubectl` yetkisi olan bir master dÃ¼ÄŸÃ¼mde Ã§alÄ±ÅŸtÄ±rÄ±n:
    ```bash
    # Calico manifest URL'si iÃ§in resmi belgeleri kontrol edin
    kubectl apply -f https://raw.githubusercontent.com/projectcalico/calico/v3.27.2/manifests/calico.yaml
    kubectl apply -f [https://raw.githubusercontent.com/projectcalico/calico/v3.27/manifests/calico.yaml](https://raw.githubusercontent.com/projectcalico/calico/v3.27/manifests/calico.yaml)
    ```

## AdÄ±m 7: Worker DÃ¼ÄŸÃ¼mleri Cluster'a Ekleme (worker1, worker2, worker3 Ãœzerinde)

1.  `master1`'deki `kubeadm init` Ã§Ä±ktÄ±sÄ±ndan aldÄ±ÄŸÄ±nÄ±z **Worker join komutunu** `worker1`, `worker2` ve `worker3` Ã¼zerinde `sudo` ile Ã§alÄ±ÅŸtÄ±rÄ±n. Komut ÅŸuna benzer olacaktÄ±r:
    ```bash
    # Ã–RNEKTÄ°R! Kendi Ã§Ä±ktÄ±nÄ±zdaki komutu kullanÄ±n!
    sudo kubeadm join 192.168.57.100:6443 --token <token> \
        --discovery-token-ca-cert-hash sha256:<hash>
    ```

    ```
    # Worker1 node'Ä±na worker rolÃ¼ ekle
    kubectl label nodes worker1.lab.local node-role.kubernetes.io/worker=worker

    # Worker2 node'Ä±na worker rolÃ¼ ekle
    kubectl label nodes worker2.lab.local node-role.kubernetes.io/worker=worker

    # Worker3 node'Ä±na worker rolÃ¼ ekle
    kubectl label nodes worker3.lab.local node-role.kubernetes.io/worker=worker
    ```
    
## AdÄ±m 8: Kurulumu DoÄŸrulama (Bir Master DÃ¼ÄŸÃ¼m Ãœzerinde)

1.  **DÃ¼ÄŸÃ¼m Durumu:**
    ```bash
    kubectl get nodes -o wide
    ```
    TÃ¼m dÃ¼ÄŸÃ¼mlerin `STATUS` sÃ¼tununda `Ready` yazdÄ±ÄŸÄ±ndan emin olun.
2.  **Pod Durumu:**
    ```bash
    kubectl get pods -A
    ```
    TÃ¼m pod'larÄ±n `STATUS` sÃ¼tununda `Running` veya `Completed` yazdÄ±ÄŸÄ±ndan emin olun (BaÅŸlamalarÄ± biraz zaman alabilir).

## CPU, RAM ve SSD Disk KullanÄ±mÄ± Ã–nerileri

* **CPU/RAM:**
    * **Master:** Min 2 CPU/4GB RAM, **Ã–nerilen 4+ CPU/8+ GB RAM**.
    * **Worker:** Min 2 CPU/4GB RAM, **Ã–nerilen:** Uygulama yÃ¼kÃ¼ne baÄŸlÄ±dÄ±r.
    * **HAProxy:** Genellikle 1-2 CPU/1-2 GB RAM yeterlidir.
* **SSD Disk KullanÄ±mÄ±:**
    * **Master:** `/var/lib/etcd` iÃ§in **Kesinlikle Ã¶nerilir!** Cluster performansÄ± ve kararlÄ±lÄ±ÄŸÄ± iÃ§in kritiktir.
    * **Worker:** `/var/lib/kubelet`, `/var/lib/containerd` ve I/O yoÄŸun uygulamalar iÃ§in **Ã–nerilir/Gereklidir**.
    * **HAProxy:** Genellikle zorunlu deÄŸildir.

## Sonraki AdÄ±mlar ve Ã–nemli Konular

* **Ingress Controller:** Uygulamalara dÄ±ÅŸarÄ±dan HTTP/S eriÅŸimi iÃ§in (Nginx Ingress, Traefik vb.).
* **Depolama (Storage):** KalÄ±cÄ± veriler iÃ§in Persistent Volumes (PV), Storage Classes (SC) (NFS, Ceph vb.).
* **Monitoring ve Logging:** Prometheus/Grafana, EFK/PLG Stack.
* **Backup ve Restore:** `etcd` yedeÄŸi, Velero.
* **GÃ¼venlik:** Network Policies, RBAC, Secrets yÃ¶netimi.

Bu adÄ±mlarÄ± takip ederek HA Kubernetes cluster'Ä±nÄ±zÄ± baÅŸarÄ±yla kurabilirsiniz.
```
kubectl delete pod -n kube-system -l k8s-app=kube-dns
kubectl get pods -n kube-system -l k8s-app=kube-dns
nano calico-rbac-fix.yaml
```

```
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: calico-cni-plugin
rules:
- apiGroups: ["crd.projectcalico.org"]
  resources: ["clusterinformations"]
  verbs: ["get", "list", "watch"]

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: calico-cni-plugin
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: calico-cni-plugin
subjects:
- kind: ServiceAccount
  name: calico-cni-plugin
  namespace: kube-system
```
Yeni token alma ve create iÅŸlemi
```
kubeadm token list
kubeadm token create
kubeadm join <control-plane-ip>:<control-plane-port> --token <your-token> --discovery-token-ca-cert-hash sha256:<hash>
kubeadm token create --role control-plane

***HASH BULMA ***
openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | \
    sha256sum | \
    awk '{print "sha256:" $1}'
************************************
kubeadm token create --print-join-command
kubeadm join <control-plane-ip>:<control-plane-port> --token <your-token> --discovery-token-ca-cert-hash sha256:<hash>
kubeadm join 192.168.1.100:6443 --token abcdef.0123456789abcdef --discovery-token-ca-cert-hash sha256:3b77e6e34a573fd12b9bfb7fdbb1fc1b1f8b33be34ac98d83a75a032be0167cc
```
## etcd Backup/Restore MekanizmasÄ±
```
ETCDCTL_API=3 etcdctl \
--endpoints=https://127.0.0.1:2379 \
--cacert=/etc/kubernetes/pki/etcd/ca.crt \
--cert=/etc/kubernetes/pki/etcd/server.crt \
--key=/etc/kubernetes/pki/etcd/server.key \
snapshot save /root/etcd-backup.db
```

* ğŸ’¡ Ã–zetle:
* âœ… RBAC â†’ Kubernetesâ€™te eriÅŸim kontrolÃ¼
* ğŸ›¡ï¸ Role/ClusterRole â†’ Yetkilendirme kurallarÄ±
* ğŸ”— RoleBinding/ClusterRoleBinding â†’ KullanÄ±cÄ±yla eÅŸleÅŸtirme
* ğŸ§° MetalLB, bare-metal Kubernetes iÃ§in LoadBalancer IP'si saÄŸlamak iÃ§indir
* âš–ï¸ HAProxy, API sunucularÄ±na gelen trafiÄŸi daÄŸÄ±tmak iÃ§in (yÃ¼k dengeleme)

